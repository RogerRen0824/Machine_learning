{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a href=\"https://drive.google.com/file/d/1iYgNRYXjGU3UCir1jyaymNswNgu6duuu/view?usp=sharing\" target=\"_blank\" >\n",
                "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Training a CNN classifier - End to End"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import necessary libraries\n",
                "import numpy as np\n",
                "from sklearn.metrics import confusion_matrix\n",
                "import pandas as pd\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "from matplotlib import cm\n",
                "%matplotlib inline\n",
                "\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.models import Sequential, Model\n",
                "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n",
                "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input\n",
                "from tensorflow.keras.optimizers import Adam, SGD\n",
                "\n",
                "# Some imports for getting the CIFAR-10 dataset and for help with visualization*]\n",
                "import keras\n",
                "from tensorflow.keras.datasets import cifar10\n",
                "from tensorflow.keras.utils import to_categorical\n",
                "\n",
                "from sklearn.model_selection import train_test_split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(50000, 32, 32, 3) (50000, 1)\n"
                    ]
                }
            ],
            "source": [
                "# Run this cell to load a subset of the cifar10dataset\n",
                "(X_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
                "assert X_train.shape == (50000, 32, 32, 3)\n",
                "assert x_test.shape == (10000, 32, 32, 3)\n",
                "assert y_train.shape == (50000, 1)\n",
                "assert y_test.shape == (10000, 1)\n",
                "print(X_train.shape,y_train.shape)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Info on the dataset\n",
                "\n",
                "> The original CIFAR10 dataset consists of 50,000 images in the training set & an additional 10,000 images in the test set.\n",
                "\n",
                "Owning to the limitations of the platform, we will use *only* 1000 images for training set, and 100 images for the test set.\n",
                "However, you are encouraged to retrain the model with the original training set to get an improvement on your performance.\n",
                "Please find instructions to load the entire dataset [here](https://keras.io/api/datasets/cifar10/)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Normalize images\n",
                "X_train = np.array(X_train)/255.\n",
                "\n",
                "# Since we have 10 output labels, we specify that in 'to_categorical' function\n",
                "num_classes = 10\n",
                "y_train = to_categorical(y_train,num_classes = num_classes)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "# A dictionary to turn class index into class labels for CIFAR-10\n",
                "cifar10dict = {0 : 'airplane', 1 : 'automobile', 2 : 'bird', 3 : 'cat', 4 : \\\n",
                "               'deer', 5 : 'dog', 6 : 'frog', 7 : 'horse', 8 : 'ship', 9 : 'truck'}\n",
                "               "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.503921568627451..1.4607843137254903].\n",
                        "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.5431372549019607..1.4686274509803923].\n",
                        "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.5196078431372549..1.4764705882352942].\n",
                        "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.5..1.5].\n",
                        "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.5901960784313726..1.4607843137254903].\n"
                    ]
                },
                {
                    "data": {
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAABiIAAAE1CAYAAABqVvgWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAABZUUlEQVR4nO3deZRlVZXg/33vfWO8F/OUc0QOkKMMgiSDmEAJiiCN1Qxav14k4IBzUa12V1evBoda8k9rW223UnRZgGWudjWDVTTl0tISlFKQGRFIyHmeYo548eZ7fn9QGW2QmXtfMuLmFN/PWqxFxj6x97n3nnvevedEZHrOOScAAAAAAAAAAAAx8I93BwAAAAAAAAAAwKmLjQgAAAAAAAAAABAbNiIAAAAAAAAAAEBs2IgAAAAAAAAAAACxYSMCAAAAAAAAAADEho0IAAAAAAAAAAAQGzYiAAAAAAAAAABAbNiIAAAAAAAAAAAAsWEjAgAAAAAAAAAAxIaNCEyZ53ny5S9/+ai+98tf/rJ4nid9fX1m297eXrn55puPqs5Bl1xyiVxyySVTygEARzKV+RAAjqVjMV89/vjj4nmePP744ydFXgAnH569jl5vb69cffXVZrvDzbk333yz9Pb2xtc5ACc81gJxNNiIOMF85zvfEc/zZPXq1UedY/fu3fLlL39ZXnzxxenrGAAcY8yHR2+mHjdwvDBfATgVMJdN3Xe+8x257777jnc3AJxkmH8xU7ARcYJZt26d9Pb2ytNPPy0bN248qhy7d++Wr3zlK6fc5PP666/L//pf/+t4dwPAMcJ8ePRm6nEDxwvz1eG95z3vkWKxKO95z3uOd1cARMBcNnWn4kYEczkQP+bfI2Mt8NTCRsQJZMuWLfKb3/xGvvnNb0pnZ6esW7fueHfphJJOpyWZTKptCoXCMeoNgDgxHwI4WTBfHZnv+5LJZMT39VeO8fHxY9QjAEfCXIYjiTqXAzg6zL861gJPLXySnEDWrVsnra2tctVVV8l11113xMlnaGhI/uzP/kx6e3slnU7LvHnz5KabbpK+vj55/PHH5V3vepeIiNxyyy3ieZ54njfxUxlH+rvV3vr3pVUqFbnjjjvknHPOkebmZsnlcnLxxRfLY489FulY1q9fL9u3b4987H19fXLDDTdIU1OTtLe3y5/+6Z9KqVSa1Oatfb/vvvvE8zz55S9/KZ/+9Kelq6tL5s2bNxG/5557ZPHixZLNZuW8886TJ554InJ/ABxfM3U+3LVrl3z0ox+VOXPmSDqdloULF8qnPvUpqVQqIiIyMDAgX/ziF+Ud73iH5PN5aWpqkiuvvFJeeumliRzWcQOYXjNxvtq2bZt8+tOflqVLl0o2m5X29na5/vrrZevWrZPaHe7vFb/kkktk1apV8txzz8l73vMeaWhokL/4i7+YOM6rr75a/umf/knOOussyWQysmLFCnn44YfNPj3xxBNy/fXXy4IFCySdTsv8+fPlz/7sz6RYLE5qd/PNN0s+n5ddu3bJtddeK/l8Xjo7O+WLX/yi1Ov1SW3DMJRvfetbsnLlSslkMtLd3S233XabDA4Omv0BTjbMZUeeyw7+XeZvdfB99GD73t5eeeWVV+SXv/zlxLH/4XFt3rxZrr/+emlra5OGhgY5//zz5R//8R8n5Tw4b/6f//N/5Ctf+YrMnTtXGhsb5brrrpPh4WEpl8ty++23S1dXl+TzebnlllukXC5PylGr1eRrX/uaLF68WNLptPT29spf/MVfHNLuIGvOjfrv8jBnAkdnJs6/B7EWOPMkjncH8P+sW7dO/viP/1hSqZR85CMfke9+97vyzDPPTEwmIiJjY2Ny8cUXy2uvvSa33nqrvPOd75S+vj555JFHZOfOnbJ8+XL56le/KnfccYd84hOfkIsvvlhERC688MK31ZeRkRH5m7/5G/nIRz4iH//4x2V0dFS+973vyfve9z55+umn5ayzzlK/f/ny5bJmzZrI/4jgDTfcIL29vXLXXXfJU089Jf/9v/93GRwclO9///vm937605+Wzs5OueOOOyZ2Qb/3ve/JbbfdJhdeeKHcfvvtsnnzZrnmmmukra1N5s+fH6lPAI6fmTgf7t69W8477zwZGhqST3ziE7Js2TLZtWuXPPjggzI+Pi6pVEo2b94sf//3fy/XX3+9LFy4UPbt2yd//dd/LWvWrJFXX31V5syZM23HDSCamThfPfPMM/Kb3/xGPvzhD8u8efNk69at8t3vflcuueQSefXVV6WhoUH9/v7+frnyyivlwx/+sPy7f/fvpLu7eyK2YcMGufHGG+WTn/ykrF27Vu699165/vrr5Sc/+YlcfvnlR8z5wAMPyPj4uHzqU5+S9vZ2efrpp+Xb3/627Ny5Ux544IFJbev1urzvfe+T1atXy3/9r/9Vfv7zn8s3vvENWbx4sXzqU5+aaHfbbbfJfffdJ7fccot8/vOfly1btsj/+B//Q1544QX59a9/bf50HnAyYS57+3PZW33rW9+Sz33uc5LP5+U//+f/LCIyMb/t27dPLrzwQhkfH5fPf/7z0t7eLvfff79cc8018uCDD8qHPvShSbnuuusuyWaz8ud//ueyceNG+fa3vy3JZFJ835fBwUH58pe/LE899ZTcd999snDhQrnjjjsmvvdjH/uY3H///XLdddfJF77wBfntb38rd911l7z22mvyox/9aFKdo51zD4c5Ezg6M3H+PYi1wBnI4YTw7LPPOhFxP/vZz5xzzoVh6ObNm+f+9E//dFK7O+64w4mIe/jhhw/JEYahc865Z555xomIu/feew9p09PT49auXXvI19esWePWrFkz8edarebK5fKkNoODg667u9vdeuutk74uIu7OO+885Gt/mO9I7rzzTici7pprrpn09U9/+tNORNxLL710xL7fe++9TkTcu9/9bler1Sa+XqlUXFdXlzvrrLMmHcM999wTuV8Ajp+ZOh/edNNNzvd998wzzxzxeEqlkqvX65NiW7Zscel02n31q1+d+Jp23ACmz0ydr8bHxw/52pNPPulExH3/+9+f+Npjjz3mRMQ99thjk/osIu7uu+8+JEdPT48TEffQQw9NfG14eNjNnj3bnX322Wrew/Xprrvucp7nuW3btk18be3atU5EJs2Zzjl39tlnu3POOWfiz0888YQTEbdu3bpJ7X7yk58c9uvAyYy57P853Fx28J31rQ6+j27ZsmXiaytXrjxs7dtvv92JiHviiScmvjY6OuoWLlzoent7J57vDs5vq1atcpVKZaLtRz7yEed5nrvyyisn5b3gggtcT0/PxJ9ffPFFJyLuYx/72KR2X/ziF52IuF/84hcTX5vKnLt27dpJdZkzgaMzU+df1gJnLv5qphPEunXrpLu7Wy699FIREfE8T2688Ub54Q9/OOnXxB966CE588wzD/mJiYPfM12CIJBUKiUib/6K5cDAgNRqNTn33HPl+eefN7/fORd5B1RE5DOf+cykP3/uc58TEZEf//jH5vd+/OMflyAIJv787LPPyv79++WTn/zkxDGIvPmr+M3NzZH7BOD4mInzYRiG8vd///fywQ9+UM4999xD4gePJ51OT/z9vPV6Xfr7+yWfz8vSpUsj9QXA9JqJ85WISDabnfj/arUq/f39smTJEmlpaYlUJ51Oyy233HLY2Jw5cyadp6amJrnpppvkhRdekL1790bqU6FQkL6+PrnwwgvFOScvvPDCIe0/+clPTvrzxRdfLJs3b5748wMPPCDNzc1y+eWXS19f38R/55xzjuTz+ch/RQFwMmAuO7q57O348Y9/LOedd568+93vnvhaPp+XT3ziE7J161Z59dVXJ7W/6aabJv0GwerVq8U5J7feeuukdqtXr5YdO3ZIrVabqCMi8u///b+f1O4LX/iCiMghfxXU0c65b8WcCRydmTr/HsRa4MzDRsQJoF6vyw9/+EO59NJLZcuWLbJx40bZuHGjrF69Wvbt2yf//M//PNF206ZNsmrVqmPSr/vvv1/OOOMMyWQy0t7eLp2dnfKP//iPMjw8PO21TjvttEl/Xrx4sfi+f8jfz3k4CxcunPTnbdu2HTZnMpmURYsWTa2jAGI1U+fDAwcOyMjIiHk8YRjKf/tv/01OO+00SafT0tHRIZ2dnfK73/0ulrkZwJHN1PlKRKRYLModd9wh8+fPnzQXDQ0NRaozd+7cSS+If2jJkiWHvFCffvrpIiLqc+H27dvl5ptvlra2tol/92HNmjUiIof0KZPJSGdn56Svtba2Tvp7zDds2CDDw8PS1dUlnZ2dk/4bGxuT/fv3m8cJnAyYy45+Lns7tm3bJkuXLj3k68uXL5+I/6EFCxZM+vPBRbS3/tUizc3NEobhRH+3bdsmvu/LkiVLJrWbNWuWtLS0HFLnaOfct2LOBN6+mTz/HsRa4MzDvxFxAvjFL34he/bskR/+8Ifywx/+8JD4unXr5IorrpiWWkfaKa3X65N2En/wgx/IzTffLNdee6186Utfkq6uLgmCQO666y7ZtGnTtPTlaPp5OH/4kywATm7Mh7qvf/3r8l/+y3+RW2+9Vb72ta9JW1ub+L4vt99+u4RheEz7Asx0M3m++tznPif33nuv3H777XLBBRdIc3OzeJ4nH/7whyPNRdP97Fav1+Xyyy+XgYEB+Y//8T/KsmXLJJfLya5du+Tmm28+pE9/eM6OJAxD6erqOuI/GPnWjQzgZMVcZs9lWr/jcqR56khfd85N+vN0/oR0FMyZwNs3k+fft9vPw2Et8OTERsQJYN26ddLV1SX/83/+z0NiDz/8sPzoRz+Su+++W7LZrCxevFh+//vfq/m0G7e1tVWGhoYO+fq2bdsm7RA++OCDsmjRInn44Ycn5bvzzjsjHNHbt2HDhkm7mRs3bpQwDKW3t/dt5+rp6ZnIedlll018vVqtypYtW+TMM8+ccn8BxGOmzoednZ3S1NRkHs+DDz4ol156qXzve9+b9PWhoSHp6OiY+POxfvkEZqKZOl8drLN27Vr5xje+MfG1Uql02D6+XRs3bhTn3KT+v/HGGyIiR3wufPnll+WNN96Q+++/X2666aaJr//sZz876n4sXrxYfv7zn8tFF13Eiy5Oacxl9lzW2toqIm8+b7W0tEzq91sd6fh7enrk9ddfP+Tr69evn4hPh56eHgnDUDZs2DDx2xYib/5j2UNDQ4fUOZo593CYM4G3bybPvwexFjjz8FczHWfFYlEefvhhufrqq+W666475L/PfvazMjo6Ko888oiIiPzbf/tv5aWXXpIf/ehHh+Q6+FMQuVxOROSwk8zixYvlqaeekkqlMvG1Rx99VHbs2DGp3cEd0T/8yYrf/va38uSTT0Y6rvXr18v27dsjtRWRQybeb3/72yIicuWVV0bOcdC5554rnZ2dcvfdd086zvvuu29aXpABxGMmz4e+78u1114r//f//l959tlnj3g8QRAc8hNvDzzwgOzatWvS17TjBjB1M3m+OljnrXPRt7/97Wn56eDdu3dPOk8jIyPy/e9/X8466yyZNWvWEfsjMvm4nXPyV3/1V0fdjxtuuEHq9bp87WtfOyRWq9WYX3FKYC6LNpctXrxYRER+9atfTXytUCjI/ffff0jOXC532GP/wAc+IE8//fSkYygUCnLPPfdIb2+vrFixwuxvFB/4wAdERORb3/rWpK9/85vfFBGRq666atLXj2bOPRzmTODtmenz70GsBc48/EbEcfbII4/I6OioXHPNNYeNn3/++dLZ2Snr1q2TG2+8Ub70pS/Jgw8+KNdff73ceuutcs4558jAwIA88sgjcvfdd8uZZ54pixcvlpaWFrn77rulsbFRcrmcrF69WhYuXCgf+9jH5MEHH5T3v//9csMNN8imTZvkBz/4wcTD1UFXX321PPzww/KhD31IrrrqKtmyZYvcfffdsmLFChkbGzOPa/ny5bJmzZrI/0jNli1b5JprrpH3v//98uSTT8oPfvAD+ZM/+ZOj2rFMJpPyl3/5l3LbbbfJZZddJjfeeKNs2bJF7r33Xv5eOOAENtPnw69//evyT//0T7JmzRr5xCc+IcuXL5c9e/bIAw88IP/yL/8iLS0tcvXVV8tXv/pVueWWW+TCCy+Ul19+WdatW3fI3KYdN4Cpm+nz1dVXXy1/93d/J83NzbJixQp58skn5ec//7m0t7dHPodHcvrpp8tHP/pReeaZZ6S7u1v+9m//Vvbt2yf33nvvEb9n2bJlsnjxYvniF78ou3btkqamJnnooYcm/ZsPb9eaNWvktttuk7vuuktefPFFueKKKySZTMqGDRvkgQcekL/6q7+S66677qjzAycC5rJoc9kVV1whCxYskI9+9KPypS99SYIgkL/927+Vzs7OQxbczjnnHPnud78rf/mXfylLliyRrq4uueyyy+TP//zP5X//7/8tV155pXz+85+XtrY2uf/++2XLli3y0EMPie9Pz8+InnnmmbJ27Vq55557ZGhoSNasWSNPP/203H///XLttddO/IO4Bx3NnHs4zJnA2zPT59+DWAucgRyOqw9+8IMuk8m4QqFwxDY333yzSyaTrq+vzznnXH9/v/vsZz/r5s6d61KplJs3b55bu3btRNw55/7hH/7BrVixwiUSCSci7t57752IfeMb33Bz58516XTaXXTRRe7ZZ591a9ascWvWrJloE4ah+/rXv+56enpcOp12Z599tnv00Ufd2rVrXU9Pz6T+iYi78847D/naH+Y7kjvvvNOJiHv11Vfddddd5xobG11ra6v77Gc/64rF4qS2PT09bu3atRN/vvfee52IuGeeeeawub/zne+4hQsXunQ67c4991z3q1/96pDjBHDimOnzoXPObdu2zd10002us7PTpdNpt2jRIveZz3zGlctl55xzpVLJfeELX3CzZ8922WzWXXTRRe7JJ5887NymHTeAqZnp89Xg4KC75ZZbXEdHh8vn8+5973ufW79+/SHPao899pgTEffYY49NfG3NmjVu5cqVh83b09PjrrrqKvfTn/7UnXHGGS6dTrtly5a5Bx54YFK7w+V99dVX3Xvf+16Xz+ddR0eH+/jHP+5eeumlQ87j2rVrXS6XO6T2wWfSt7rnnnvcOeec47LZrGtsbHTveMc73H/4D//B7d692zxPwImOuSzaXOacc88995xbvXq1S6VSbsGCBe6b3/zmxPvoli1bJtrt3bvXXXXVVa6xsfGQfmzatMldd911rqWlxWUyGXfeeee5Rx99dFKdg/PbW+e9I737Hpy7Dhw4MPG1arXqvvKVr7iFCxe6ZDLp5s+f7/7Tf/pPrlQqTfreqcy5h7sWzjFnAlHN9PmXtcCZy3PuLb+LCAAAAADHWG9vr6xatUoeffTR490VAAAAANOMfyMCAAAAAAAAAADEho0IAAAAAAAAAAAQGzYiAAAAAAAAAABAbPg3IgAAAAAAAAAAQGz4jQgAAAAAAAAAABAbNiIAAAAAAAAAAEBs2IgAAAAAAAAAAACxSURt+Nfrvq7GK+XQzNHYppcL0vo/V+EF9r7JWJ/ej7Bi9zPfqtcZH9Jz+AnPrFEq6jVqJT2H79v/tEeQ1M93S1OLmWPlshVqvLOrU413dOhxEZHXNr6uxp9/6Xk1XiiPmTWSWT3uG+dKREQq+jXzRvRr4iTCuPBqajzTnFLj6aDBrBGO6v2o1/Q+iIhUKxU1/plPfdbMcbL5ux89oMYzDRkzR9+u3Wq8XCiq8VDs+UtEH4e+H2X/WW+TSuvHms4aN5yI1Jw+DjvmzlLja979LrNGR7LFbAMAAAAcHyNG3Hp/zEWoUTXi6Qg5MJM99Nu/UeNR3i89LzDi1vfbaym+0STKa7C1zpYw1/rqdhFvav9Mb1i3a5j/EnBdvx4iIvWaniQ04i7CqfB9vR9J43wnEvZxJJJ6m1TGHltJo05onPByxT4Z5bK+Dlep6PF63V4rCo1xUa/Z58J5+o30xxfeYubgNyIAAAAAAAAAAEBs2IgAAAAAAAAAAACxYSMCAAAAAAAAAADEho0IAAAAAAAAAAAQGzYiAAAAAAAAAABAbNiIAAAAAAAAAAAAsUlEbtjgqXEvbafyk3qOStnog69/v4iI1EM1HOrhN9uI3qhu7N9UqnaRWt3pDTz9WBuyjWaNd6xapcYveNcaM8ex8M7lq9X43O65avzRnz1i1ih742o8DI3rISJBSr/ufq6u96Fojwvn9BzVkn6ThDWzhNTG9X7UanaSRBB56jhlFAdH1Pjw/n1mDmuYeYmkHg+rZg2TMbeIiFh3Q61aUeOJlD0+8i3NajxI6Pfbhq3bzRrBEj1Hq9dk5gAOpyYlNZ6QzDHqCQAAODEVI7TJGnH93SCa9DTkwIzmjLdDK/5mIyNuvKO6CAt51o9ZR0jhjH6E5jqefS58oyOe8b4eYVVUPKtVlDUBs42x9ursGubpMnKYxxkhR5RxYQ3fwNcHX2o6pnLjMGpVe+xZ655ehPEbZexY+I0IAAAAAAAAAAAQGzYiAAAAAAAAAABAbNiIAAAAAAAAAAAAsWEjAgAAAAAAAAAAxIaNCAAAAAAAAAAAEBs2IgAAAAAAAAAAQGzYiAAAAAAAAAAAALFhIwIAAAAAAAAAAMQmEbWh5+nxhqbAzFEth2q8PKbHh424iEi9qscTSeNARKQ0pu/P1EM9RxhhfyeR03P45aQav/LyK80a8+ctMtucDLrb5qnxOV16XERk/ZZX1XgqkzZzVPyKGk9m9WvqRdj2C/QSEqT1+yyRsIuEZac3MO4hERH7Ljr1JBvyarw+WjdzZJtyeo2cHh/atdOsEdb1edK4+iIi4vv6OHJOP9ZQ7HMhTh9olcKYGu/r1+dIEZEXiq+r8XQyZeZobWpU4yvmTsc8a50v+/PVNmrE9ePEZANhWY13+Zlj1BMAAHB8WGsT2WPSCyB2zng3NNbHRETEM95Czbhdwhkp3DR009X1Bp5vv20bp1OceSBmCftgI5wMz+hHGOpx6zDebGP100wQoYg+V4f1CAt1CWOtz/r2wK7hjIN1xvK9bw1eEakb18wz1pLe7MfU8RsRAAAAAAAAAAAgNmxEAAAAAAAAAACA2LARAQAAAAAAAAAAYsNGBAAAAAAAAAAAiA0bEQAAAAAAAAAAIDZsRAAAAAAAAAAAgNiwEQEAAAAAAAAAAGKTiNpwfMSp8cJQ1cwR1vQc9ZL+/XXnmTW8hL63UqvrfRARGR0M1bif0PvhBfb+TiqZVOPvfvfFanz+vEVmjZnirHecabbZuHWjGq+W6maOZF6/ZkE6pcadq5g1nBjjMzDCaaOBiKRCvZ9hhPss8GfeHma2vV2Nu7o+b4iIJLMZNT5v6RI1nvLs+Wv3ps1qPEjq119EJHR6HbMbod3PoQODajyVKarxhsacXWNAz1EulM0c+xr0a7a374Aan9Vin2+p6XPDvHlz1Hi1VjNLtOdm2/1AZM2+Pf4AAMDJbL8R7zomvQCOO+PdUOzlA7OR/fZoc0Y/Q/t1XTzjRTc04n6E93XraD3jXHlR1mKMNR0X4WRYr/TOuqbWuBERZ3TDWWtTEcae2Q1nn0/zSDy9I36EfiaMxT7rXHiefU19Y9nTi9DRWoS1HrMfU84AAAAAAAAAAABwBGxEAAAAAAAAAACA2LARAQAAAAAAAAAAYsNGBAAAAAAAAAAAiA0bEQAAAAAAAAAAIDZsRAAAAAAAAAAAgNiwEQEAAAAAAAAAAGKTiNqwMFBX467u2UmMbQ/n9HiQMhqISCIdqPF6xe5nvWrUqetxV6uZNebM71XjZyw918xxcqiYLeqFITUe5JrU+OyOHrPGytOWqfHnf/+SmSPtpdS4ZwzgIKWPTRGRerWqxl1Nvw+9tFlC/LR+D/gJe38ySNrHcqppam9R45kI56R/7141Xh8vqfH2ufPMGkPDo2q8MjZm5vDrxnzv6WOoZoxjERE/qY+zd567XI1nM/r9KCKy78B+NT4u9mfK4NCQGi8V9PNZG8uaNVqb9GPZu3+3Gj99/mqzBqaXLxGeeQAAp4SyEY/w+I0TTl+ENlxZQETEGescnovwXOwZa2jGa1mUJ28X4d3OzjG1Z/xQf40WEZHAqOEF+nuy79nrNcbruoQRfiTdM69ZqMftEubYqtf1GmFor8EExvn0IpxPa1x4vt4PP8qvAHjGsRpn1EX4PQPrmiQinAvzZo2A34gAAAAAAAAAAACxYSMCAAAAAAAAAADEho0IAAAAAAAAAAAQGzYiAAAAAAAAAABAbNiIAAAAAAAAAAAAsWEjAgAAAAAAAAAAxIaNCAAAAAAAAAAAEBs2IgAAAAAAAAAAQGwSURvWKnrc85xdLK3ve3hJ/fuDwCwhntEmSHl2EkNY0481k8iaOa59/41T7sfJwR4Xvqdfk8KBfWo819lj1njn2eeo8edfe8nMEUpNjderdTUeZNNmjURavyXrJb0PUe5DcXobI/yvdew2p5rC0JAar1X1ayMi5sndvXmbGu/omWeWWHXeeWp8w7PPmTlGBwfUuGcMgGKhaNa46CL9njxn2QV6ArffrLGsd44a37Blq5njhdHtarxa0T8cB/r1eUFEpFjUPxsX9C42c+DYmoFTIADMWIGERgt+tu/YKpktnIyqcU/aI9ThugJvmoYnX2uNwVqjiNIFP8JChtUNo6PWWokfoZ/OM9ZFfSMeYTHGamOU+Nc2xsF6+nuui7CwZJ9v/ThcaC8Se8YisR/hZHjWPWD00/x+sdfyrH6a10si3CIRxq+xbB8Jn64AAAAAAAAAACA2bEQAAAAAAAAAAIDYsBEBAAAAAAAAAABiw0YEAAAAAAAAAACIDRsRAAAAAAAAAAAgNmxEAAAAAAAAAACA2LARAQAAAAAAAAAAYpOI3NIZYSMuIhLWQzUepDy9RkWPi4hUS3U17iftQw6S+v6MtXtzzVXXmDVmiq2vrzfb1Ov6NVvcu3DK/WjJdavxfEvezFEP9H5mchk1XhX9+0VEQmNwVStVPV6umDVEvw0lrNXMFBXfPpZTTUt7mxofHhg0c6Sz+hhxxhRXLYybNRKtLUaLCJO1Z8zFoT6I/CAwS5y+ZGr3da2/YLZJdOg1li6cbebYuPWAGh8Z1+85F9rn2zn9cymds+cnHFsJscc4AODUMFbZqcYbUgvMHKnp6swpwXiPcHvUcLFoV8g2zHsb/QGg8byp//yyMxYMrXjEIlNOYb26Ga/J4rwI7wjOOp9WEbvEdPB9vZ8J452/Zqz/ioh4xrmwLmm9bp+M0GgTaexZCzXWt0cpYdTwjPdPz4twvj29I7419kTEC6Y+H/AbEQAAAAAAAAAAIDZsRAAAAAAAAAAAgNiwEQEAAAAAAAAAAGLDRgQAAAAAAAAAAIgNGxEAAAAAAAAAACA2bEQAAAAAAAAAAIDYsBEBAAAAAAAAAABiw0YEAAAAAAAAAACITSJqQ89sYLaQIKGXSwb6vki5VDVrJJNpNV4bq5k5ap5eZ8XKFWq8d/4Ss8aJoN5/wGwTtHfoDSojanjn3j1mjZERPUdTQ4Ma7+xtNWuI1NVoJhWYGcaKZTUeOqcnCO2xl23IqHGvqNeoV/TjFBGRmj6+/Sj38gzcwmxqalTj6bR+7UREDhhjpDRe0OOVilmjv69fjbt6aOawLm/o6ceRTNofLQnj88D8/o6FU/r+qFaftUqN//qF36vxIJkyawSizw3F4pgab8kZ8zQAADhq5XH9c7hQ3GnmmNU8T43bbyIni/1mi/LQsBpPt3Sp8WxD89vqEYCpsZcH7PdLMd4fRay4vUZhLcdEyWGt6fhmCrMT9su2kcK5KJ8Y+jXxInzqeL7ekSChn4wwjFCjZpyMUD+Oet1e/6qHeg3noixuGcfq9HiUGnXjWD3jRvQijG+7jZ3D96b+xDIDlxMBAAAAAAAAAMCxwkYEAAAAAAAAAACIDRsRAAAAAAAAAAAgNmxEAAAAAAAAAACA2LARAQAAAAAAAAAAYsNGBAAAAAAAAAAAiA0bEQAAAAAAAAAAIDaJyC09PRy6cIpdEQlrTu+CHn4zh1T1eGDnCERv9MH3/bGd5ARQ3bFZjb+yaZuZY+nSxWo8m8+p8e62drNGYyajxpvyeSODPfaGRvfoDdL2nlwySKvx0nhdjecbG8wa2bReY2HvAjXuRbgN9V6KjI9XzBxdbS12oVNMZ1ebGt++dYeZI/T1iTTb1KjG/YQ9Zdeq+iDwkvoYExFJZPWxWiuPq/EgsCfabNbux4mgo3WRGj97+bAa3zdcNmtUKnqbwBg3AAAgPtl0kxqvSdbMUTDeY5tOko/68vgmNV4olswcbe0rp6s7wHFgLUqdJDfzCcabhtPmTUMSz7h+zlj3DJ29aOmsMeTp79J+lHdDp68beL79vu57+jtqOtA/+8JQXzMQEalLTY27qt7PKOtfYd24ZmGEa2Y1cda4iTI2jTVJa9gY40ZEJJhaiWnDb0QAAAAAAAAAAIDYsBEBAAAAAAAAAABiw0YEAAAAAAAAAACIDRsRAAAAAAAAAAAgNmxEAAAAAAAAAACA2LARAQAAAAAAAAAAYsNGBAAAAAAAAAAAiE0iakNvGlrUKjU1HjqjghehFzU9SZSdl7PPeqdVJUIWgzMOdscONVz2KmaJdKmsxpMDg2aOvfv2qvH2Wqsar5RLZo2O5hY1nk5m9AShfS6Gh0fVeK2kj00RkWQ+qeco19W4swa4iCSMMe6JXiMMzBJSEf1YvdbQzpG2r+upJpVsUOMLFy8xc7R1dqvxREK/gLt37DRr7Nimzx3pfKOZo3PeHDW+Z9MGNZ5K2gPR9yIM1pPAgtn6dfdTe8wc42V9DnM1e34CMD30T1mRU2PmwslowPgoaIv8Voe3q1KrqvGmRv19SERkvLZfb5Doejtdik0t1PtpvXa1BS12kZEBPZ7L6fEIawKyr18Njw3pcRGR/Nz5eoOmZrsfOKlUxV4fSYp9v8809irH1NcTo6wFTocox6KK0k/PWJW01oSirIsa79q1etHM0eTrc2B362lqPDNfXz8TEfn95qfUeCEc0xNEWGMLjeUtKy4i4oz1W+eMaxJlYBk5nJkkyrjQ435g57D7YeM3IgAAAAAAAAAAQGzYiAAAAAAAAAAAALFhIwIAAAAAAAAAAMSGjQgAAAAAAAAAABAbNiIAAAAAAAAAAEBs2IgAAAAAAAAAAACxYSMCAAAAAAAAAADEho0IAAAAAAAAAAAQm0TUhp6nx33faBAhh4R6A8+ZJcRL6DnampvNHO+95Eq70FQVRtXw3n171Hg9GZol5s6Zq8a7Mg1mjr7RYTU+nNG/f2x8zKxRHB9X4015vZ9eXf9+EZE9B/ap8XKpZuZIpvQBmG7Qbyc/sAdwNdCv6/ahXWq8XLbHRa1SV+N+0kwhw3mj0Qo7x8nm9fWvq/GzzzjLzNGUyavxgaI+L5TG7LEuVX0spxsbzRSnrVqp92NwQI3XqiWzRjJoN9ucHPTzmc/qc6iISEM2q8bbGua9rR4BOHpVIx5MQ40DRrxzGmrgxFIY22y22ffaC3oOr0mNp8+93KyRM1vgcMZL+nNPKBGez4KyGq4m9OeJpOjPCtMl4Xep8aLxjvqzXz9h1vCd/r7+Rx9dq8ZrtYJZ46cv/EaNjw6PmDk+3DvfbDNlB/RxYX7qdEZezkEESWbJ48YzFwuPTQ4xUjhj/pII66JWEWfFrT6IiOfra09NuTlmjuHNep1Nxjz7R++1n0tWLDxHjT//2mN6At/+2XrfM9pEOJ82/Xy7CGvZVptpGd92L+wWzl5ztPAbEQAAAAAAAAAAIDZsRAAAAAAAAAAAgNiwEQEAAAAAAAAAAGLDRgQAAAAAAAAAAIgNGxEAAAAAAAAAACA2bEQAAAAAAAAAAIDYsBEBAAAAAAAAAABik5iuRJ7v2Y2sNqFTw0Fg75u4hJ7jXeeda+Y4FgZ37lTjO/bo8UTOPt8d3W1qPJXOmDlkuF/vR2NajWf8wC4xWlDjI8NDany8aJaQbTu3q/HQGHsiIl6oxwOnj09XNRKISDVRUeO5jpxeY79+LkVEEnWjH1V7bDWLft1PRW+8+qoaP/OMs8wcHUZ8yNfHUOjZ16Y4MqLnCKtmju1bt6lxP61ff69WMmvMFC0N8yK0suaGCJ+vAKaF9WS0cXBYjW9/42WzRqGSUuP57h417tdHzRqnz9bn6Vkt880czDzR1QvPqPEdv9ef60VEagX9s7Nt6elqXH9CxFQk9VtWRMbNHOOj+jtVJt2pxhPBsblnx7bsUeO/fPw3anxnqWzWOG3VyrfVp7d68cX1ZpsdO/ercc+z3/2eeu45NX7+uy8zc5ief0OPp4yreumqqfchEuvZPsK6wgmgf2S3Gi+X9M94EZE5XcunqzsnjQivoBGSWHHjnozUB72RNy2zpLUmaddwRhNn5Yiy9mpctNaGWWaKcy85w6hhd8PWrkaz2UY1XqnYi4Geteod4Xxab+u+MXxDZ68FmuPXuKZhOPUaobVWKCKh2OtJFn4jAgAAAAAAAAAAxIaNCAAAAAAAAAAAEBs2IgAAAAAAAAAAQGzYiAAAAAAAAAAAALFhIwIAAAAAAAAAAMSGjQgAAAAAAAAAABAbNiIAAAAAAAAAAEBsElEb+oG+ZxHWQzOH5wdqPJnR40HKM2uk0lk1fuay1WaOKevvN5ts37ZdjY8WC2rciTNr/Ob3v1fjC2t5M0dDVY/7g0U13pbOmDXSeX1sDY8OqfGNw31mjYGBQTXu12pmDpfV+1kZ13OURstmjcA4XckFaTXe2KyPfxGRIGn0c9i+lzsS9tg51fQsWqTGO6ahRms6p8ZzOT0uIuIb82ytaI/DoT5jDnPG/OPbe9z7Rvao8e6m2WaOUwc/EwCcLDKlfWr83BX23PXT37yuxrc+t1uNh27ErFEaa1XjtQUDZo4w0HPkOxao8XazwoniDbPFwJaNarw0qr+jeH6jWWP22eep8fa2uWYOxGO8oN9zgfGeLCIiof58PTa+X43vc/Y9e1rTmXoD+3VHHv/pj9X4luEhNZ6fNces0TFbf6a2FEb09zoRkbrTDzabtN9Rx/qG1Xh5vT6Xp/fo78kiIjKuP5cPDexS4zuestcd3nH+hWp8rGaPrfGifs67GpeZOSz7hvTP1+aWNiODfR+OGvdySn/VnsGMzzjPXqczUoiZIkoJq0aUJPYym/7tU/x+Efs4opTwAj3J7kH72ee3v3hejV952RVqvLXT/jywXHLGH6vxnzx7n5kjmUip8Sjj13N6m9C48PUIA8P39DZhaPTBeM4QEXFGP5zRBxGRcKo3ibD6AQAAAAAAAAAAYsRGBAAAAAAAAAAAiA0bEQAAAAAAAAAAIDZsRAAAAAAAAAAAgNiwEQEAAAAAAAAAAGLDRgQAAAAAAAAAAIgNGxEAAAAAAAAAACA2bEQAAAAAAAAAAIDYJCI3zARq3I07M0cYhmrcT+jdCQO7xrJFy8w2U2Z0Y9uGjWaK0cKI3iDtqeGdA8b3i8jw2AE1nuhcYOboTTfoOQo1Nd6cSZk1UrmkGn9+t34+t+7Vj1NEpFquqPFsQh/fIiJBYNwDxsBwdbOESE2vUegbU+ONKfuWtm6jTDpj5mhvajLbnGo+cN75U86x34qPDanx5lldZo32nnlqfOSAfb/Uq/r90tjUqMZrEebqRFq/7wHgRJRN6M89TY0tZo7AjavxhoT+wFBz9uf01h16PyuFQTPHhWe1q/GUDKnxIWkxa9gtLBHeP0ZfUONbN+8wc+zZPazGC2X9+WvFRReZNdrb5pptcHyUSvp71+ho0czR1qI/O+UD/bmorWHq4+Plnz9mttk8rD+tjof6PTcrmzdrdHdP7VgG+qwnapF6TZ9HnWe/mC1dvESNp+vGXDxoz7Oy5iw13NK+Wo/bFUz5RLfdptFuM1XdLVOrsb3fXoMZGtXfg9qT+ufeTOXpS1MiYjaIUGSqfZiGIiJiPVd4RkeseBRmDbHXrjxffy5JN9rrRr2LOtT4o4/8gxo//92XmDWWLDldjXvGGtzyRWebNbbsedWoEeGaGdckdPq4sdbCRUTE139PwPotAqMLkdq4KPeIZ48/C78RAQAAAAAAAAAAYsNGBAAAAAAAAAAAiA0bEQAAAAAAAAAAIDZsRAAAAAAAAAAAgNiwEQEAAAAAAAAAAGLDRgQAAAAAAAAAAIgNGxEAAAAAAAAAACA2icgt004Nu3KEPQ2n5wirNTWeSmfMEpde8Ed2P6aovG2HGu8b6DNzJNKeGt83XtJrDI6aNcK6fr4Hi+NmjgW5RjWe9gI1nkk3mzWGaoNqfHu/fj5rY2Wzhh/o57ueMlNIXepqPKyFarxqjG8REWf0ozau96FW0o9TRKTB02/7hmTazJHI6tcdh1cc08fya6++rsZXrTrDrLFs1So1/vLTz5g5Egl9Ps83N6nxMVcxa6TSDWYbHKTP5SL2fQ9gegzXkmr8lV/+ysyxdYM+14uvPww05OaYNYLsbDW+ba+ZQvznX1XjV112mpGhxS5iekONblqv91FEZPde/TlxtM/+zJKE/g7id3So8XmdPXYNnLBcqD/j+4H9jJ9I6s9WuYz+WZ6RVrNGpX+XGv/dG78zc5Tr+ruG9T5+ySXvNmukjGN1Tj/fH7rhT8war/5OP9bXn3vezNGeM55VN+7T4215s4a02+sbiMbV7bm8b5++7pBN6WsfIiKiT/cz07S8ikzH+47eJlIGX5+rPc+oYcTfbBOhI4ogYa/FJHz9fM5unmvmqFf0z53W9+g5TltiPSfKlMdOT9uZZpvhQr8aHykN2IWMceGMte4ThdVPF9rH4Yy11Sj4jQgAAAAAAAAAABAbNiIAAAAAAAAAAEBs2IgAAAAAAAAAAACxYSMCAAAAAAAAAADEho0IAAAAAAAAAAAQGzYiAAAAAAAAAABAbNiIAAAAAAAAAAAAsWEjAgAAAAAAAAAAxCYRuaHRMgwCM4cztj1qQVWNL+5ZbNYQsfthKuv92Lljhxr3qmWzRDVVV+P7RsfUeBiGZo1KRa8xXBo3c5REr1Ms19R4PpU2a9TH9RqVuh5PJM0SEiT1AZxstJNk8xk17qf0Ae77JbNGqaiPnfqofk2db9/SmZx+j4wn9GsqIrJhYK8a7zUzzExN2QY1XhjR78mBoYJZY353uxpPRbgnxdPvuY6OVjU+t6vZLBFMx1w9Y3jHuwMA/tWi2aep8W3b+swcfm2rGg+d/jkcpIfsGqE+xy6Y02XmuGLNO40WHWYO2241umfjdjU+YJ9uKYwV1Xhbc9bM0bNUfwd5fteoGt9jVhCZHaENjo+6/vgtzU05M0ciqb8njI7p735+4nWzxgu/eEaNjzkzhWQbm9T4pZetUeOdXd1mjQOD+ru2lzMWDer6/SYi4vv6RauJfTI2PveCGj9j1gI9Qbs9t8i4fi6kqs9f0txo1xD9/bI2NmhmKHr651Jjbr6RwT7fr67/jRrPNehjs2is4YiIVI3X8fJ4xcwxE3nWu4izr29opPA9/b73PPt9yOxnhHcqzzfWdKx++nYN33gN9gJjDvTs8+0HxrpQ3c4xe9YsNZ5KR5jjTgCL5y9T48+++mszh2+dc+OyRxkX1hC3bjM3DePbRVhnFmN9Ngp+IwIAAAAAAAAAAMSGjQgAAAAAAAAAABAbNiIAAAAAAAAAAEBs2IgAAAAAAAAAAACxYSMCAAAAAAAAAADEho0IAAAAAAAAAAAQGzYiAAAAAAAAAABAbBJRG/p+Wo3XXNXMEdZDNe65pBp/7wV/ZNaYDn0bN6nxUmFET5Cya+waG1bjYaWmxl3dM2vUQqfGy7UI18zV1XhnW5ueIBGYNSp1/VitPiTz9jD29KEnfl0/VyIitbLej0RCL5LJ6eNbRCQM9RqVml4jm7JrNLe2qPHR4ZKZozJmnFAcVmvQoMbXnLtCje+p2JOLH+hjINmSM3MURwt6A2OcLulaYNYQsecGIA79Mq7Gq2J/HoSh/rk1x29+W33CqePS8y8w27hQ/wxd//S/qPHS8KhZI5cqq/Fr1rzfzCHSEqHNkb321ANmmy39Y3oPmtvVeGum0ayRn6u3Wb6sx8wh2dlqeFVefzfQZx2c6ELjnk2k7eezmujP1/VAf9fe/tIWs8Yr2/ep8bDBvl8uu/R8Nb5ooX6/7Nm1y6wxMqR/hvZv6VfjO3ZuNWs4Y5mjqaXTzLHkjDPVeHFUv7OzURYF3tipx6v6uRLRz5WIiLiKGk5krRoijafPMVroc+COTRvNGiN9+rEUfP3zIpOx33HmNOnvYs0NvJ8cjufpP7/snP3s7Hn6+pUV9434mzmm/nPWvq/nsON2P4OE3iYI9HFohEVExPP1z63xcXvNJ9WYtQudBIpl67nZngOd8TP8vq9fFM+z7xHzFdS6h8Qee9Y7bJR7OTTWmaPgNyIAAAAAAAAAAEBs2IgAAAAAAAAAAACxYSMCAAAAAAAAAADEho0IAAAAAAAAAAAQGzYiAAAAAAAAAABAbNiIAAAAAAAAAAAAsWEjAgAAAAAAAAAAxCYRtWG5UFPjtXLdzFGpVNX40rmnq/FkMm/WMBWLZpPB/gNq3ElFje+tjJk1BooFNZ4MjsEeUdJu0rAgozeopfR4adysMezp5yu0+lkPzRphzVPjlVF9bIqIBEa8UnFqPJmyT3gyo7fJNqX17w/04xQRKdf18Vsb1+91EZEw8syBt2Nhy1w1/vvX3jBzpJL6SG1I58wc5RH9vnWhPtZ3DW43a2RT+hzXlusxc1i2l/rV+IJM+5RrnAj+Zc9rZptsoN+053SdNl3dOa5GxJ6/KqLPk2Nl+3OrUi6r8TlNzWYOzFyXXXiRGq/171DjWzaPmjXqxnPN4B7786S1SZ83Rg7oz7L7B8wSUhnT79mh0l41PphuNWuEjfpna2FrycxxxhJ9XuhpazFzTN0+NVoLs2aGhN80XZ2ZUWplfZyORniP8NL6Z0+qqj9bvfHKFrPG7oL+ntvdZD8Drlh2lhrfuPF5NV4c0T8fRURKQ3qbJUv0Z8Bs1n4RGTX60dbVa+ZoWNipxn//mj5Xrzp9vllDrKGzS3+Wlc177BolY45L2O/SEg7q8ZXdajhI6e+wIiJzOvQcZWNdoa3ZfvZqb1mgN8jp9+GMZS4x2GsQnqe38Y34dPB9e43N6udU42/2Q39fDwI9HuU4fE9vkw6mYW31JNGR1u97P3jZzGFdkyChn2/n7LnFGjtWCucizOXGuIjSz1CmPk/yGxEAAAAAAAAAACA2bEQAAAAAAAAAAIDYsBEBAAAAAAAAAABiw0YEAAAAAAAAAACIDRsRAAAAAAAAAAAgNmxEAAAAAAAAAACA2LARAQAAAAAAAAAAYsNGBAAAAAAAAAAAiE0iakMv7dR4siWwi417avyq914etTtHbd8bm8w21XJRjQ/VSmp8Z/+AWaNUrqnxRtHPZ0I/lSIi4oveyEvb1yw5K6fGa6MpNV4YGDdrDDm9TTan1whLdbOG6KdbXDk0UyRb9H27VD6td6FWMWt4gX7NKqWy3ofGrFkjYVz2RNren/S9CAPwlFMw4vq9EoU+y4oM9+03c5Sq+v3QM2++mSOXb1DjhaI+B44cGDJrZDNJNd62tMfMYdm894Aab+1tN3M0TrkX8ZvdMc9ss3XHNjX+k+GXzRwu0EdowpgXVvbYY6/F18deUapq3BmfnSIizuk55qU7zByFtH4PAFNx3oX6Pd3SstfMsX1Tvxr/7a9eMnO8Y/kCNZ5J6/frgjmdZo05YZMaL3h6jU399vNbcVx/dhrfar8bNAb6s2prUn928pz9rJppyut96FihxhP+THw2OzaCQB9n46P658qbjYwxMK7nqDW2mSVyef0zsDfCM2D/gR1q/MXnX1Hjjflms0b3/DlqvOzpzxv10HixE5Gx0SE1vmiFfT7HrEd/p7+jGq/ib7JeD0eMd2nPngPFeL80+yAiYo3xx19Qwx2z7RLJtP4e63L6u9a+vfvsIglj+Ss79fe5U5E1lF2EtQHPm9rPQEdZfvCmYY1iqjmifL/VxoxH+Hly5/R5NBNhLVBkxIjrz3AnDmNuMT5zRESCQD/nQWCdT7uGiP6c4ESf761rLiIiod5PF+FZMqhN/fcZ+I0IAAAAAAAAAAAQGzYiAAAAAAAAAABAbNiIAAAAAAAAAAAAsWEjAgAAAAAAAAAAxIaNCAAAAAAAAAAAEBs2IgAAAAAAAAAAQGzYiAAAAAAAAAAAALFJRG2YatKbumpo5liwoEeN51o6onbniMZe36LHBwfNHGWvqsb3F4fVeL2qf7+IiG+fLlUyYe8hJeqBGi+MFM0cW7btUuNjuTY1XirWzRp7BvXzGRYqajwI7GHsWecrrZ8rEZFELqXGc7m8Gg9rNbOG5/R+1EQ/nwlnn4uGXIMaz3Xa56I1lTHbnGp++cxv1Pi82XPNHMmkPobe2LVfjefSabPGUF+/Gh/M2Ne3Z44+F+/btk2NjwyPmDU+eOb7zTaaHWV7/vKMz6VixZ6rG1PJyH06Wq+P7lbjXY1z1HhHstGssT2hj73At+fqRKDPo62Nej/6R8fMGnsrA2rc9/U++BE+D1obm9S4Z98i0iQzbw7EdNLn0NG9+nPRvA77s2BWTn/mrpT1ZysRkdK4Ppc7p8/D2aT9rFpOtqvxjfv1eXysWDZr+AX9c3H3gT1mjn3b9efh5uZWNX7GOeeYNc7uON1sg+NjaHRUjbe36eNYRCRf1z835uW61fiiBfaHU7myXo27CD+D+POf/Ysar1b1HMmkZ9Z4+eUNanx/WX8muSLZZdZYlGvWG+yx50BZkFXDqzr0ayY77Odh2aSvXUi5pMedXUKSxrNR2X5Hlbz+/igH9HsktXGzXWNWpxoezOrHsWu//gwpIjJa0q/74vQyM0cwEx8BnXVf2wPROatN/D8j7Xn2/GS18Y14hBIixrmwzlWU2z40cuQb7WdJEf15tDjap8azjYsi1IjfpqFfq3FrihQR8T39fPq+HvciLACHTm/jmeMiwsgIjBoR1qkjjXEDvxEBAAAAAAAAAABiw0YEAAAAAAAAAACIDRsRAAAAAAAAAAAgNmxEAAAAAAAAAACA2LARAQAAAAAAAAAAYsNGBAAAAAAAAAAAiA0bEQAAAAAAAAAAIDaJqA2TmaQar0nFzHH+eaujlju84aLZZGygT43XwpKZY+/YsBrvHymocc+z93dSSb1N6AVqPGHERUTyKb1NNp0xcwzs0s/XcLBbr9HUatZobu1W4+mgSY0nUymzRr0WqvGEMb5FRBJpvU1D0jifKc+sUS/X1XiQ1G/ZRMI+jnRaP19B0h5bDRl77JxqCmPjavx3r7xi5vAT+rl1yQY1Xk/kzBoNef3aFO2pWqpO72e1WlPjTfm8XWSK5qSzZpv1oX6/dKXs+8Xyyli/3oc3XjNzeE6P7+8YVeNNzfY8m0jp56IwPGbmmDdXn6uX5ueocX0WflNR9LFVlaoa7ysMmTWGxkbUeGuzPX7z/BzHSWpThDb6GJNQH6O739hlVqhU9Puxb78+Ubd3258FbXM71HjoIjyrNuh1hoYH1fjo0D6zRovTP1sXNunPLJWS/cwyELapca+r0czhAr0fZeP7x0pT/7zB8dPkN6vx04uzzBzZPuM9oKa/76T79WcBEZELkvrn1+P9B8wcpXF9NFer+kPLSEH/jBUR8X09xwXldj1BaMRFRKr6fS8b7DUBGTWeNQf26/FdT9k1fOM9trlTjzfp7w4iIjJuXJMRff1EREQG9fEpc2er4bHXXzRLjJX0sbe5rr8nj2bsd4PMqP75+vpzL5k5VrzfuN+9CNfkJGO8qphxERHPaOWcHvc8ey3FajMdOaxXgAglxEU6Y5oIb1VGP3LSY6bY8Nrv1Hhjuz4XZxvt90t7Sdpad7KewET2D+hrloFvL4v7vv68GQT6wIiwfCu+cdGse8RFGBeBMYDD0B6bUca4hTdpAAAAAAAAAAAQGzYiAAAAAAAAAABAbNiIAAAAAAAAAAAAsWEjAgAAAAAAAAAAxIaNCAAAAAAAAAAAEBs2IgAAAAAAAAAAQGzYiAAAAAAAAAAAALFhIwIAAAAAAAAAAMQmEbVhvVJV4+2tbWaO7raFUcsd1uD2rWabSrmkxsfqelxEZO/AoF6jUtMTeJ5Z44wzzlLjbS3tanz/vv1mjUq1rsaTyaSZI5kw9qqcfi6aIowL5wVqvNqoj716GJo1POfUeDbXYOYIfL2fYV0/F2GEfb+qlNW4b4wt37fHnhfq/SiXK2aOcqlgtjnVDA6M6A0i3PepVEqNJ3x9Sg5SGbNGMpNX46Wafj+JiLhAnxvyzS1qvDx0wKwxVfrd+KaurjlqvBghhzVLbt/Zp8ZDZ18z674dGNE/t/qHd5k1rLm6Oj5mpli4dKUat2a4KD/50Gg+luhxP6fP9SIiWdHn+7SZAUdH/3xzha1qfNOmTWaFHbt2q/GREXucixhzuZdTwyljDhYRWXia/jx89h9doMYDz35mORZyTUaD+VOv0TG2RY3PnWt/9m7YN67GCxV7dhowXh/6R/UGewr6MzlObL2Bfs9t3rTPzLGy07gh5nXp8YG9Zo356awaHx4cNnM0GDlKJX2sl6v6XC8iks3oz8ONdT0uFftdRYYH9Lj1jisi0qTP97LnDT2+134+68vpzzUd1kdK7jSzhozr11Qy9pqAlEf1uDHFPZO0n9ybjFf6hrT+hNaUsz9/gzF9fA5Ujfc9Ealt1T+XEgv15+WTkTPWUrwIaxAi9jN63LwI7+ueMTVYcYmyHhOhHxrn7O93obFmKfaawGnLV6jxPfv05+6+fvtzK5vV79tcwyw1/vsD/2zWCAL9onmRVhamtg7nmQNH7Jdlz7iHotQw2tRq9tpqOA33Mr8RAQAAAAAAAAAAYsNGBAAAAAAAAAAAiA0bEQAAAAAAAAAAIDZsRAAAAAAAAAAAgNiwEQEAAAAAAAAAAGLDRgQAAAAAAAAAAIgNGxEAAAAAAAAAACA2iagNi/0FNb50xflT7kx1y2417vyKnSNVU+PD43UzR//QmBpvbM2p8Xy+yazR2tyixnOZtBpvbsqbNUbG9GtWq9rnc7QUqnFPnBqv1wfNGuVKVY1Xq3q8XCmbNQJf33Pzgwh7ck4/Vj0qUqtbLUQqZf2apFL6LZtIeGYN3w+MFlZcpFjSz/nqd73LzHGyKZX0ceh59rmvlvX5J+mNq3EX2tcm6eljuWwch4jIhg3b1PjCOR1qvDQ6ZNYYqupzQ0uy1cxhWdmqz5OvlezPg7HiqBofqetzpEtlzRqer4+dqjF1OGdf07Cm1/C8lJlj/S59XJw193QzR9xapOF4dwFHpD/X9I03q/Gdg/qzl4jIhn36/dbYsdDM0TZ3vhrvXbJEjQ/39Zk19hWLanyZxzg+yMvr16zRfhyWd7ZPvR/WVd2tP3LLYnv44gS2Z/ceNR70nGEnsZ6ND+jPG1LU35NFRKSivweXjOd3EZHAeA+w38vs98smZzzPZvTjkKo9z8qY8WxU3G/n6Nukx/29anhjo/6MKCLive9CNd6xZKWe4JUXzRpywLjuDZ12jv5danhrdViNj6Xsz7WOsv7A22q8w7SvmG3WyF64Wo1Xd+vHKSKSaJh5n9HmW26E92BnrJY4Y60lQi+mhdVPz+rHNHTTPBfmuRIJRZ9/+mrG/CYijWGbGm9o0OfydNp+D86k9Ae5naO/VePFsvHZKSKBr7+DRPn5fM+zxq/1/WYJsxu+saZpLAO92cYYoFHWtOyVTxu/EQEAAAAAAAAAAGLDRgQAAAAAAAAAAIgNGxEAAAAAAAAAACA2bEQAAAAAAAAAAIDYsBEBAAAAAAAAAABiw0YEAAAAAAAAAACIDRsRAAAAAAAAAAAgNmxEAAAAAAAAAACA2CSiNmwMm9X42UvPtZMUi2o42VRX420LzzRLtMmwGq+88ryZo6c0R42n8kk1PndOq1kjCCpq/MC+ATU+MqafSxGR0YLeplLR+yAiUiyW1HjVyJFM2kOs7kI1XqlU9e+v698vIuJ5+p6b53l2jim2qIfOzFAP9WNJp9NqPJXSx6aIfS6ymYyZIzSu2amoVtXHYZQRYp23WkK/fplMo1lDqvo9m8ra17dYKKhxTzrVeE9vr1ljw9adanxWS78an9+5xKxhzT5hzbqmIn19+lwclvUczrf3+6tOb+O7mhr3Qj0uIlKr6226WlvMHHM79eu+Z3SXGp/dONesgZmrs3OWGr9kjR4XEblgjR7XP0GnSWPXsaiCY6zDiueOSTdwnBSz+uyxYI7+7hiJM97t+vaYKaqzWvQGvv2eMDY6rsZrxntXWLefe5zxXCP1HXq8XDZr2J2I8POYpaweNx79B845zSxx3pKVdj80K8+y27z4oB4fs1PsH9Gf2wvdxiTo2c/cgdFmnm882c/uNmtIpkUNJzv19ygREfHtd75TjrVWEmktRb/nnOhrJRGWUsRIIZ7Yaxi+C/QSzigSpaOBsTZljDHrXImI1Gv6PNmRWGzm6B88oMabcm1qPJnS15BFRGqyV42PD+trF2fMu9yssX7vU2q8VIlw3zv981MfNSLObCESePp1nYbbUDxfrxHlNxWCwD4WC78RAQAAAAAAAAAAYsNGBAAAAAAAAAAAiA0bEQAAAAAAAAAAIDZsRAAAAAAAAAAAgNiwEQEAAAAAAAAAAGLDRgQAAAAAAAAAAIgNGxEAAAAAAAAAACA2iagNb7zh3xgt0maOarVPjSfbG6N2R5FTo7N7G8wMzQt71fjoSFGNL+iaZ9bI+p1q/KknnlfjlUrVrFGv1dR4lF2oZCKpxp3x/aHVQETK1bqeo+6pcc+zjyQI9DaJRMrMYR1tEARqPIxwMqp1/VxYNbLZjFmjXKqo8fHxMTOHPwO3MM2rF+jjVETE1UI9Xi6r8WqUaxO0qvFMSu+DiIinDzPZOzisxuefvsCsURnWPw/md/aYOaZqad6+X14Z1+d7SRgny0U430a8Huo56jV77KV8/TO6p7vdzNGW0j9f66m8Gq+KPr5FRJIRniWAI2H0AIhD99xlanzWXPu5x1Qt6XH9lUxERArGc2QmYb/6L+jRn7+SSb0jm7fuMGt0JI1np8ERI4P+jvsm42UltN+lpaK/M4016M9FjXPnmCX6B/ep8fbWNiODPTBKzXo/k1t/Z+bYHRjPs6GxBpOwP6FPb9XXR2RwQA33PfWCWaN//SY9XiqYOS64fI0a9/RTcVLyPONdw4qLiLNepo0UEZaV7BxmJyJw+jzq7FMhNeNoKhV9Lm9IZs0a87uXGy3sgZpq0Nem9g/o78kt7fq7oYhIOWxW411t+jtq3159XUJEZOmsy9T4UGmXmWNodLsaL9X79QSBve4QBPp8bq17emKvOzhjbcJFGcDm6oVtBi4nAgAAAAAAAACAY4WNCAAAAAAAAAAAEBs2IgAAAAAAAAAAQGzYiAAAAAAAAAAAALFhIwIAAAAAAAAAAMSGjQgAAAAAAAAAABAbNiIAAAAAAAAAAEBsElEbNrdUp1ws2dRhtFivRkdGXjZrbH69T43PmTfbzDFn9kK9QYNnZEiaNSrFvWq8PDaqxosjw2aNUrGi56jY17QWOj1e1+NBoMdFRDpntapxPxGo8d3b9ps1xkb0Y/V8u58i+nV3RoowDM0KvmeMLU/fOxzUh/+/5rD6YO9PJhKRp45TRt24wOmkPk5FRPLNTWq8MFxQ47XRfrNG4On9KHt5M0c2m1HjIwcOqHHv9MVmjaXzl5tt4qYf5ZtOnz9Pjb+yeYsaDwL786DmanoO45o64/tFRFavWqTGe7MtZg6RkhoNIp1Ri/W5ZJ9PAACmU8/K1bHX2L5/nxpfEOE5sympfw7/f++5yMzRuvQ0vUFNf5+p7bdfRhKBcSw//Wc9vmOnWUNC44XHenETEfH1HANNDWp8fm+PWSLfoL8bTMfPjW7L6ue7NWHX8AP9XASFMTW+0M+ZNRLGNSsm9WfAqjWuRKQ2qj/Llox1BxERr6HZbHOqsZYowij3k+htPM+KW2twIs7oR4TlGPH9up7D15NUyvr7vIhIU65djZ++8EI13uXNMWtYChHORbHWqMarxtSxp1+fF0REfE9fVwqr+vk8cMD+PPBS+udakOo1cyzo1Nc3QtE/+/aOvWLWKIf6sXrm2qo+dkXsjz7npn6fRcFvRAAAAAAAAAAAgNiwEQEAAAAAAAAAAGLDRgQAAAAAAAAAAIgNGxEAAAAAAAAAACA2bEQAAAAAAAAAAIDYsBEBAAAAAAAAAABiw0YEAAAAAAAAAACIDRsRAAAAAAAAAAAgNomoDev1shoPgo0Rsiwy4rPUaFPTMrPCWe+K0I0TQCrbpcbXXKkfa6F/r1mjXA3V+P6+ITPHWGFMjSf8QI3PmZs3a3TNmW200PfLNm7eYtYY7htX49VK3cxR10+nOHFqPJGwb7eGbEaN12o1PYFnlhDf18+nF2F/cnxcP5+nooSnn5fiSMHMUTDapFP69U/lWswaXlK/J8PCkJmjHur9aGhsUOO/27nLrHHpvLlmmxPBuW3Narw1rX+uvbhpp1ljrKjf12VjbpnT0mTW6M22mG1s+riYHsljUAMAgOlUjdBG/3yr5rNqfCjCM35LoD8DthrPsiIisnGrHh8aUcMJ64VJRKSlTY+f+Q49fvaZdg3jfUdC451KRGS3/r5d3bdbjaeMZ/I3WdfE6qf9flnJ6WOraJ0rEWkzHs/qvt6PPRm7xtaq/n6Za9XHTSHC6R4K9WdqydvP1EWnH6t+tk9W1gRknNcIbawKnhelhtEDZ0+k5XJJjSeSaTV+xuIrzBrzsgvUuHXX7xuNsHZlnK5aWDFzlEr6uahW9M8+V7f76Yy5OKzr8XS60awxPDyq9yEomjnGi/p7cDbdosbzwRlmjXx2nxofKm1W486zPw880a9JaM2RIuIifMxb+I0IAAAAAAAAAAAQGzYiAAAAAAAAAABAbNiIAAAAAAAAAAAAsWEjAgAAAAAAAAAAxIaNCAAAAAAAAAAAEBs2IgAAAAAAAAAAQGzYiAAAAAAAAAAAALFJRG04uCdQ47XKmJmjsXm7Gk9mcmo8lSuaNUTSEdpYnBHXz8X0SKrRXPt8M4N+NkXaZvW8jf6cuJYsarUbLYq/H6eOitmiPtZ/DPpxgnH6vBB49r6uZ8TDel2NV0YGzRq14rgaT7d1mDnqnv7RkA9CNZ4Y3W/WKMtcNT4dM/mxsDjXpMabVi40c/QNl9R4S04/G7PTDWYNAAAQF/29TUSk7gpqfNv2HWr8gOjPXiIiS0r6c6L3q8fNHO3GM6CUjfcE41lWRETSWT2+wHhHXTjPrmE9dNcjvM8bj/YpIz48MmKW6GxvNFro16NcsN8Nkln9fA8H9jtMd6C/B5WcfsK3luz3y/FAP9bsqL4WNBqWzRqFmt6P07pnmTmyubzZ5lTjrPnHut9ExDMaeZ6xBmct0YmIGDkqVXsctjfp88ua098XoSO6/YWaGh8v6u+Grm7fs9W6fj+Mjuw1c6SN85lu0cfFjoHXzRqeMXfUa/pniqtGWIMZ1T+j04l2M0eTMS7GUxk1HtpDT/JNc9R4S4e+JjBcW2/WqOtDT5z9qCFhGKGRgd+IAAAAAAAAAAAAsWEjAgAAAAAAAAAAxIaNCAAAAAAAAAAAEBs2IgAAAAAAAAAAQGzYiAAAAAAAAAAAALFhIwIAAAAAAAAAAMSGjQgAAAAAAAAAABCbRNSGO7ZtVeMNmayZY3BgQI37fqDGE4m0WaNeK+k5kkkzRyqVUeNjhTE17vn2/k4q0I/V8/Tv932jgYgERj+CwM6RTOnnK5nQjyPw7SHmnB63zmdoJRCRWr2qx2t6XMTup5WjXqubNfL5vBpPGOc7rIdmDSfGgYR2P+t1vU17fraZ42TjjNu6HmFb1wuNc28MssCzx7rnamrcr5XNHKHTx1mhrB9se4Pdz10jB9T4oqZOM8fJoDOwPxs72+w2AADg5LV500Y1vnfvHjXuMvqzmYjI/rTeJiX2u3SipD9HupoezwT2A3HeeF/3X35BjSdffsas0WGsGzTU7H5mU3qbdHebGm/JNZg1piqdazXbDBVG1PiIvTwiYqwJFIwXpVrCXhMYLYyr8f2FPjVeivCe1N7drcYXLVli5qiL/r4dnII/62utH9hnXsT39PPiibE25dnrHOWKvh6zZP5ZZo4zZp1jttHsLehzpIjI2Jj+Pl413tcHx94wa5y1dJUa3zyor82KiOSMOay5u0mN7ynbIyNprUk6Y4IK7TXNelW/JqWxnWaOHXt2qPGGlL7+1dm12KwxUtDHeLGUU+Ots5abNYa89Wq85uy1IhdG3kY4olNvlgQAAAAAAAAAACcMNiIAAAAAAAAAAEBs2IgAAAAAAAAAAACxYSMCAAAAAAAAAADEho0IAAAAAAAAAAAQGzYiAAAAAAAAAABAbNiIAAAAAAAAAAAAsWEjAgAAAAAAAAAAxCYRtWG5WFPjwwN7zRyhC9V4Y0NGjdcidLceVtV4Om3nSKX0fpRKJTWeTARmjXo6rcdD/VwlPM+skUzqx+rb3ZSEfqhidcM5u4YYbbJZ/XpUa/rYFLGvWSLCNfN9fd8urOvXLAztk1E1uhGkk2rcRalhnK9avW7mKJcrarzdzHDySWf0cdje2GjmGDzQp8atMRIkU2YNF+iDyDfiIiJ+whhnnt6PMMLkMjIyqDdo6jRzAPEoRGiTi70XAIBTx2lLzpxS/FipVwbU+MjwiBovFotmjYHBITU+PjymxqvjZbPGawU9R71ivOSKSKWqt3ElvR/nDY+aNdozrXofKvpxpFL6M7uIyK49+9V4IWGvjwzX9Zd+6x22Gtg//1pM6f0ohfqx+oF9HNkm/X1t157dZo7hUf26Ll+63MxxqrFXpkScsTDkefoYqdfsNYrFC96pxs/oPtvMYc0ue/v1dZBq3V6bGhzdqsb7C6+p8VowbtYouwVqPKxHWLMs6W3KxjUNQ3tk1J2xxmasi3oR1hut9Y/GVnsezTXq42/owE41vnmzPg+LiCyYt0qNd8xdosYHDthrRQ1tK9V4SV4wc9QjrL9a+I0IAAAAAAAAAAAQGzYiAAAAAAAAAABAbNiIAAAAAAAAAAAAsWEjAgAAAAAAAAAAxIaNCAAAAAAAAAAAEBs2IgAAAAAAAAAAQGzYiAAAAAAAAAAAALFJRG3Y2NCixndt22XmGC+Nq/FZ3XqNvnLNrDFUGFXjuUSEvRdfb1Ove/r315xZIpUM9BShniMV2MeRCPQa4hnHISJJ43wlEnqOtNUHEWnKp9R4Jq3HnXGuREScM9pEOBfOhWo8NGrUI4wLP9BvyWqo92G8WDFrlMp1NV6p2fdZqVxV471nvtfMcbIJjXM/0Ndn5nBGjsDX7xffmJtERLxAH2cRbklJJvV7Tjz9OGo1+37yUq12R4DjIhuhjX4P8HMeAICTUZBqU+OtnUY8Qo05C95Gh46rshqt1fR4IhF5qeWIUsYz+T//7Gdmjn37D6jxmvWeLCIj+uujuLrx/li1nptEEoH+/tDY1KzGc/m8WSObzajx0DoOEUmnpn5dTzURhpC53BIaazrdHaebNc7sPluNG8NYRER2D+jrKeNlfU3zwMBzZo1Cfbca93z9XCSc/UJfLBfUePNs+35padbn+53Dm9W4uQYnIjVn3HPG1OFFGHsS6u9l+srWv9Yx1kVbZjWq8fG0fj1ERHbs0MdO4OkjONHQadYY2q1/psya/04zx7bCU2YbC2/KAAAAAAAAAAAgNmxEAAAAAAAAAACA2LARAQAAAAAAAAAAYsNGBAAAAAAAAAAAiA0bEQAAAAAAAAAAIDZsRAAAAAAAAAAAgNiwEQEAAAAAAAAAAGLDRgQAAAAAAAAAAIhNImrD8nhRjdcqNTOH53lqPEwEenxM74OISFiqqvGxpL33kmpIqfFaWFfj46N6H0REgkA/F3UJ1XjKOJciIqHT45WqXkNExPP1Or7Rj7ndzWYNl9BzbNo1oMYL42WzRrmqj8/Q2edTxDihnh539ukWEWNchHqSeoTjcMbACK2BI+aZOCUljHGajDCdlkN9bgiN+148exD5Rj9S+jQrIiKBUSeXa1DjmUzarOGVh9T4wJg+z7blZ5k1gKPDz2gAAAD9eTaRsJ93p6q/b78ab2xqNHOsWLlUjTc12jmy2ZwaTyX0Zyfft9+T0hl9DSaT0s93Y95ed0hm8mYbHIaxxuD5ERY6jByptD4OV/dcZNcw7By01+lKlTE1vmP/k2q86vrMGr5vvJAb5yrK0tVLW55X44Fxz4qIpIsZNV6tlvQaEdZH6qK/81vLI1EWpjwzidEHEfHtoaNKNNmfFw0Jfc3ytU2/VeNLe99l1giSbWp89IA+D4uItDQsMdtYeNsGAAAAAAAAAACxYSMCAAAAAAAAAADEho0IAAAAAAAAAAAQGzYiAAAAAAAAAABAbNiIAAAAAAAAAAAAsWEjAgAAAAAAAAAAxIaNCAAAAAAAAAAAEBvPOeeOdycAAAAAAAAAAMCpid+IAAAAAAAAAAAAsWEjAgAAAAAAAAAAxIaNCAAAAAAAAAAAEBs2IgAAAAAAAAAAQGzYiAAAAAAAAAAAALFhIwIAAAAAAAAAAMSGjQgAAAAAAAAAABAbNiIAAAAAAAAAAEBs2IgAAAAAAAAAAACx+f8BVfO/y5e6Fd8AAAAASUVORK5CYII=",
                        "text/plain": [
                            "<Figure size 2000x1000 with 5 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Let's look at some sample images with their labels\n",
                "# Run the helper code below to plot the image and its label\n",
                "num_images = 5\n",
                "\n",
                "fig, ax = plt.subplots(1,num_images,figsize=(20,10))\n",
                "for i in range(num_images):\n",
                "    image_index = np.random.randint(0,1000)\n",
                "    img = (X_train[image_index] + 0.5)\n",
                "    ax[i].imshow(img)\n",
                "    label = cifar10dict[np.argmax(y_train[image_index],axis=-1)]\n",
                "    ax[i].set_title(f'Actual: {label}')\n",
                "    ax[i].axis('off')\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Building the CNN"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Convolution\"</span>\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1mModel: \"Convolution\"\u001b[0m\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
                            "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
                            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
                            "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
                            "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
                            "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
                            "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
                            "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
                            "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
                            "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
                            "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
                            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
                            "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
                            "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
                            "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
                            "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
                            "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
                            "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n",
                            "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,253,674</span> (4.78 MB)\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,253,674\u001b[0m (4.78 MB)\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,252,266</span> (4.78 MB)\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,252,266\u001b[0m (4.78 MB)\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> (5.50 KB)\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,408\u001b[0m (5.50 KB)\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "\n",
                "# Build a CNN that takes the (32,32,3) images as input,\n",
                "# and gives out 10 outputs that give the probability of each class\n",
                "# We suggest a model architecture in the hints, but feel free\n",
                "# to use your own variation\n",
                "\n",
                "___\n",
                "# Your code here\n",
                "def build_basic(kernel_size=3, input_shape=(32, 32, 3)):\n",
                "    model = Sequential(name='Convolution')\n",
                "    model.add(Input(shape=input_shape))\n",
                "    \n",
                "    model.add(Conv2D(32, kernel_size=kernel_size, padding='same', use_bias=True))\n",
                "    model.add(BatchNormalization())\n",
                "    model.add(Activation('relu'))\n",
                "    model.add(Conv2D(32, kernel_size=kernel_size, use_bias=True))\n",
                "    model.add(BatchNormalization())\n",
                "    model.add(Activation('relu'))\n",
                "    model.add(MaxPooling2D())\n",
                "    model.add(Dropout(0.25))\n",
                "    \n",
                "    model.add(Conv2D(64, kernel_size=kernel_size, padding='same', use_bias=True))\n",
                "    model.add(BatchNormalization())\n",
                "    model.add(Activation('relu'))\n",
                "    model.add(Conv2D(64, kernel_size=kernel_size, use_bias=True))\n",
                "    model.add(BatchNormalization())\n",
                "    model.add(Activation('relu'))\n",
                "    model.add(MaxPooling2D())\n",
                "    model.add(Dropout(0.25))\n",
                "    \n",
                "    model.add(Flatten())\n",
                "    model.add(Dense(512))\n",
                "    model.add(BatchNormalization())\n",
                "    model.add(Activation('relu'))\n",
                "    model.add(Dropout(0.5))\n",
                "    model.add(Dense(10, activation='sigmoid'))\n",
                "    \n",
                "    return model\n",
                "\n",
                "# Define the EarlyStopping callback\n",
                "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
                "    monitor='val_loss',  # Monitor validation loss\n",
                "    patience=20,         # Stop after 250 epochs with no improvement\n",
                "    restore_best_weights=True  # Restore the best weights found during training\n",
                ")\n",
                "\n",
                "\n",
                "# Compile the model\n",
                "\n",
                "model = build_basic()\n",
                "model.compile(optimizer=Adam(),\n",
                "              loss='categorical_crossentropy',\n",
                "              metrics=['accuracy'])\n",
                "\n",
                "# View a summary of your model to see if the architecture is correct\n",
                "model.summary()\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/300\n",
                        "\u001b[1m201/625\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.3207 - loss: 2.1138"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[10], line 9\u001b[0m\n\u001b[0;32m      4\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# keep a validation split of 0.2 to begin with and fit the model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# your code here\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32mf:\\Anaconda3\\envs\\pytorch\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
                        "File \u001b[1;32mf:\\Anaconda3\\envs\\pytorch\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:318\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    317\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 318\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    320\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
                        "File \u001b[1;32mf:\\Anaconda3\\envs\\pytorch\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
                        "File \u001b[1;32mf:\\Anaconda3\\envs\\pytorch\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
                        "File \u001b[1;32mf:\\Anaconda3\\envs\\pytorch\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "File \u001b[1;32mf:\\Anaconda3\\envs\\pytorch\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32mf:\\Anaconda3\\envs\\pytorch\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
                        "File \u001b[1;32mf:\\Anaconda3\\envs\\pytorch\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
                        "File \u001b[1;32mf:\\Anaconda3\\envs\\pytorch\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
                        "File \u001b[1;32mf:\\Anaconda3\\envs\\pytorch\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1567\u001b[0m   )\n",
                        "File \u001b[1;32mf:\\Anaconda3\\envs\\pytorch\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "# Fit the model with the training data\n",
                "# Specify a batch size, and number of epochs to train\n",
                "batch_size = 64\n",
                "epochs = 300\n",
                "\n",
                "# keep a validation split of 0.2 to begin with and fit the model\n",
                "# your code here\n",
                "\n",
                "history = model.fit(\n",
                "    X_train, y_train,\n",
                "    epochs = epochs,\n",
                "    batch_size = batch_size,\n",
                "    validation_split = 0.2,\n",
                "    callbacks=[early_stopping]\n",
                "\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Write the code to plot the following:\n",
                "# - Training loss\n",
                "# - Validation loss\n",
                "# - Training accuracy \n",
                "# - Validation accuracy\n",
                "# Your code here\n",
                "\n",
                "# Function to plot the training history\n",
                "def plot_training_history(history):\n",
                "    # Plot training & validation accuracy values\n",
                "    plt.figure(figsize=(12, 5))\n",
                "    \n",
                "    # Plot accuracy\n",
                "    plt.subplot(1, 2, 1)\n",
                "    plt.plot(history.history['accuracy'])\n",
                "    plt.plot(history.history['val_accuracy'])\n",
                "    plt.title('Model accuracy')\n",
                "    plt.xlabel('Epoch')\n",
                "    plt.ylabel('Accuracy')\n",
                "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
                "\n",
                "    # Plot loss\n",
                "    plt.subplot(1, 2, 2)\n",
                "    plt.plot(history.history['loss'])\n",
                "    plt.plot(history.history['val_loss'])\n",
                "    plt.title('Model loss')\n",
                "    plt.xlabel('Epoch')\n",
                "    plt.ylabel('Loss')\n",
                "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "# Call the function to plot the training history\n",
                "plot_training_history(history)\n",
                "\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import the mini test set\n",
                "x_test,y_test = np.load('cifar_Xtest.npy'),np.load('cifar_ytest.npy')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preprocess the test set \n",
                "X_test = np.array(x_test)/255\n",
                "\n",
                "# Convert test labels to one_hot encoding\n",
                "num_classes = 10\n",
                "y_test = to_categorical(y_test,num_classes = num_classes)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate the model to get the model metric specific\n",
                "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
                "\n",
                "# Print the accuracy\n",
                "print(f'Test loss: {test_loss:.4f}')\n",
                "print(f'Test accuracy: {test_accuracy:.4f}')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get the predicted label numbers by using .argmax() function\n",
                "y_pred = np.argmax(model.predict(X_test),axis=1)\n",
                "\n",
                "# Use the same function to get the predicted label numbers for test set\n",
                "y_labels = np.argmax(y_test,axis=1)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get the confusion matrix for the predictions\n",
                "# Read more about the confusion matrix here\n",
                "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
                "cf_matrix = confusion_matrix(y_labels, y_pred)\n",
                "print(cf_matrix)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find below the helper code to make a nice plot of the above confusion matrix\n",
                "def plot_confusion_matrix(confusion_matrix,cifar10_dictionary,ax=None):\n",
                "    df_cm = pd.DataFrame(confusion_matrix, index = cifar10_dictionary.values(),\n",
                "                      columns = cifar10_dictionary.values())\n",
                "    sns.set(font_scale=1.2) # for label size\n",
                "    ax = sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16},cmap='YlOrBr')\n",
                "    ax.xaxis.set_ticks_position('top')\n",
                "    plt.savefig('confusion_matrix.png')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Here we call the plotting function\n",
                "# Observe the most misclassfied entries\n",
                "# and discuss ways to improve performance\n",
                "fig,ax = plt.subplots(figsize=(12,8))\n",
                "plot_confusion_matrix(cf_matrix,cifar10dict,ax=ax)\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Improving model performance\n",
                "\n",
                "As you would have noticed, your model starts to overfit on the training set.\n",
                "You may employ several ways to remedy this: \n",
                "1. Get more training data (use the entire CIFAR10 training set)\n",
                "2. Use Data augmentation\n",
                "3. Use other regularization methods"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
